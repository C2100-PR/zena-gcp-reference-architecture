ai_infrastructure:
  vertex_ai:
    endpoints:
      primary:
        region: us-west4
        machine_type: n1-standard-4
        min_replica_count: 1
        max_replica_count: 10
        accelerator_type: NVIDIA_TESLA_T4
        accelerator_count: 1
      secondary:
        region: us-west1
        machine_type: n1-standard-4
        min_replica_count: 1
        max_replica_count: 5
    
    models:
      super_claude_1:
        framework: CUSTOM
        region: us-west4
        version: "1.0.0"
        machine_spec:
          machine_type: n1-standard-16
          accelerator_type: NVIDIA_TESLA_T4
          accelerator_count: 1
      
      claude_v3:
        framework: CUSTOM
        region: us-west4
        version: "3.0.0"
        machine_spec:
          machine_type: n1-standard-16
          accelerator_type: NVIDIA_TESLA_T4
          accelerator_count: 2

  llm_configuration:
    super_claude_1:
      endpoint: us-west4-api.coaching2100.com/claude
      memory: 96GB
      api_version: v1
      features:
        - content_generation
        - bid_processing
        - document_analysis
      monitoring:
        latency_threshold_ms: 500
        error_rate_threshold: 0.01
    
    claude_v3:
      notebooks:
        - name: claude-v3-notebook-1
          region: us-west4
          purpose: content_automation
        - name: claude-v3-notebook-2
          region: us-west4
          purpose: analytics
      
    vm_deepmind:
      instances:
        - region: us-west1
          machine_type: n1-standard-16
          memory: 96GB
          purpose: specialized_processing
        - region: us-west4
          machine_type: n1-standard-16
          memory: 96GB
          purpose: ml_operations

  serverless_config:
    cloud_functions:
      - name: llm-processor
        runtime: python39
        memory: 4GB
        timeout: 540s
        trigger_type: http
      - name: model-coordinator
        runtime: python39
        memory: 2GB
        timeout: 300s
        trigger_type: pubsub
    
    cloud_run:
      services:
        - name: zena-api
          cpu: 4
          memory: 16GB
          min_instances: 2
          max_instances: 10
          concurrency: 80
        - name: model-gateway
          cpu: 2
          memory: 8GB
          min_instances: 1
          max_instances: 5
          concurrency: 40

  testing_framework:
    unit_tests:
      framework: pytest
      coverage_threshold: 85
      directories:
        - src/llm
        - src/api
        - src/processing
    
    integration_tests:
      framework: behave
      environments:
        - staging
        - pre-prod
      components:
        - llm_integration
        - api_endpoints
        - data_processing
    
    load_tests:
      tool: locust
      scenarios:
        - name: peak_load
          users: 1000
          spawn_rate: 50
          duration: 30m
        - name: stress_test
          users: 2000
          spawn_rate: 100
          duration: 1h

  deployment_pipeline:
    cloud_build:
      triggers:
        - name: pr-validation
          type: pull_request
          branch: main
          steps:
            - name: test
            - name: build
            - name: security-scan
        - name: deploy-prod
          type: push
          branch: main
          steps:
            - name: test
            - name: build
            - name: security-scan
            - name: deploy
    
    artifacts:
      repository: artifact-registry.googleapis.com/api-for-warp-drive
      regions:
        - us-west4
        - us-west1
      cleanup_policy:
        max_age: 90d
        max_versions: 5

    monitoring:
      metrics:
        - name: model_latency
          threshold: 500ms
        - name: error_rate
          threshold: 1%
        - name: memory_usage
          threshold: 85%
      alerts:
        channels:
          - email
          - slack
          - pagerduty
        severity_levels:
          - critical
          - warning
          - info